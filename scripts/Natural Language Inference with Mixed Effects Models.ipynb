{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Inference with Mixed Effects Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from typing import Tuple\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from torch import softmax\n",
    "from torch.nn import Module, ModuleList, Linear, LogSoftmax, ReLU, Sequential, CrossEntropyLoss, BCEWithLogitsLoss, Dropout\n",
    "from torch.optim import Adam\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "from fairseq.data.data_utils import collate_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "## MegaVeridicality\n",
    "\n",
    "We first pull the [MegaVeridicality v2](http://megaattitude.io/projects/mega-veridicality/) data from the [MegaAttitude website](http://megaattitude.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>list</th>\n",
       "      <th>presentationorder</th>\n",
       "      <th>verb</th>\n",
       "      <th>frame</th>\n",
       "      <th>voice</th>\n",
       "      <th>polarity</th>\n",
       "      <th>conditional</th>\n",
       "      <th>sentence</th>\n",
       "      <th>veridicality</th>\n",
       "      <th>acceptability</th>\n",
       "      <th>nativeenglish</th>\n",
       "      <th>exclude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>surmise</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone surmised that a particular thing happened</td>\n",
       "      <td>maybe</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>update</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone updated that a particular thing happened</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>disregard</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone didn\\'t disregard that a particular th...</td>\n",
       "      <td>maybe</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>agree</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone agreed that a particular thing happened</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>surmise</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone didn\\'t surmise that a particular thin...</td>\n",
       "      <td>maybe</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  list  presentationorder       verb   frame   voice  polarity  \\\n",
       "0          487     0                  1    surmise  that_S  active  positive   \n",
       "1          487     0                  2     update  that_S  active  positive   \n",
       "2          487     0                  3  disregard  that_S  active  negative   \n",
       "3          487     0                  4      agree  that_S  active  positive   \n",
       "4          487     0                  5    surmise  that_S  active  negative   \n",
       "\n",
       "   conditional                                           sentence  \\\n",
       "0        False  Someone surmised that a particular thing happened   \n",
       "1        False   Someone updated that a particular thing happened   \n",
       "2        False  Someone didn\\'t disregard that a particular th...   \n",
       "3        False    Someone agreed that a particular thing happened   \n",
       "4        False  Someone didn\\'t surmise that a particular thin...   \n",
       "\n",
       "  veridicality  acceptability  nativeenglish  exclude  \n",
       "0        maybe              6           True    False  \n",
       "1          yes              2           True    False  \n",
       "2        maybe              4           True    False  \n",
       "3          yes              4           True    False  \n",
       "4        maybe              3           True    False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver_url = 'http://megaattitude.io/projects/mega-veridicality/mega-veridicality-v2/mega-veridicality-v2.csv'\n",
    "\n",
    "ver = pd.read_csv(ver_url)\n",
    "\n",
    "ver.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "Next, we remove non-native English speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>list</th>\n",
       "      <th>presentationorder</th>\n",
       "      <th>verb</th>\n",
       "      <th>frame</th>\n",
       "      <th>voice</th>\n",
       "      <th>polarity</th>\n",
       "      <th>conditional</th>\n",
       "      <th>sentence</th>\n",
       "      <th>veridicality</th>\n",
       "      <th>acceptability</th>\n",
       "      <th>nativeenglish</th>\n",
       "      <th>exclude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>surmise</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone surmised that a particular thing happened</td>\n",
       "      <td>maybe</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>update</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone updated that a particular thing happened</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>disregard</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone didn\\'t disregard that a particular th...</td>\n",
       "      <td>maybe</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>agree</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone agreed that a particular thing happened</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>surmise</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone didn\\'t surmise that a particular thin...</td>\n",
       "      <td>maybe</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  list  presentationorder       verb   frame   voice  polarity  \\\n",
       "0          487     0                  1    surmise  that_S  active  positive   \n",
       "1          487     0                  2     update  that_S  active  positive   \n",
       "2          487     0                  3  disregard  that_S  active  negative   \n",
       "3          487     0                  4      agree  that_S  active  positive   \n",
       "4          487     0                  5    surmise  that_S  active  negative   \n",
       "\n",
       "   conditional                                           sentence  \\\n",
       "0        False  Someone surmised that a particular thing happened   \n",
       "1        False   Someone updated that a particular thing happened   \n",
       "2        False  Someone didn\\'t disregard that a particular th...   \n",
       "3        False    Someone agreed that a particular thing happened   \n",
       "4        False  Someone didn\\'t surmise that a particular thin...   \n",
       "\n",
       "  veridicality  acceptability  nativeenglish  exclude  \n",
       "0        maybe              6           True    False  \n",
       "1          yes              2           True    False  \n",
       "2        maybe              4           True    False  \n",
       "3          yes              4           True    False  \n",
       "4        maybe              3           True    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver = ver[ver.nativeenglish]\n",
    "\n",
    "ver.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MegaVeridicality contains judgments to the same items presented under two different prompts: \n",
    "\n",
    "1. Conditional prompt: If someone \\_ed that a particular thing happened, did that thing happen?\n",
    "2. Unconditional prompt: Someone \\_ed that a particular thing happened. Did that thing happen?\n",
    "\n",
    "We remove responses to conditional items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>list</th>\n",
       "      <th>presentationorder</th>\n",
       "      <th>verb</th>\n",
       "      <th>frame</th>\n",
       "      <th>voice</th>\n",
       "      <th>polarity</th>\n",
       "      <th>conditional</th>\n",
       "      <th>sentence</th>\n",
       "      <th>veridicality</th>\n",
       "      <th>acceptability</th>\n",
       "      <th>nativeenglish</th>\n",
       "      <th>exclude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>surmise</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone surmised that a particular thing happened</td>\n",
       "      <td>maybe</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>update</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone updated that a particular thing happened</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>disregard</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone didn\\'t disregard that a particular th...</td>\n",
       "      <td>maybe</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>agree</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone agreed that a particular thing happened</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>surmise</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone didn\\'t surmise that a particular thin...</td>\n",
       "      <td>maybe</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  list  presentationorder       verb   frame   voice  polarity  \\\n",
       "0          487     0                  1    surmise  that_S  active  positive   \n",
       "1          487     0                  2     update  that_S  active  positive   \n",
       "2          487     0                  3  disregard  that_S  active  negative   \n",
       "3          487     0                  4      agree  that_S  active  positive   \n",
       "4          487     0                  5    surmise  that_S  active  negative   \n",
       "\n",
       "   conditional                                           sentence  \\\n",
       "0        False  Someone surmised that a particular thing happened   \n",
       "1        False   Someone updated that a particular thing happened   \n",
       "2        False  Someone didn\\'t disregard that a particular th...   \n",
       "3        False    Someone agreed that a particular thing happened   \n",
       "4        False  Someone didn\\'t surmise that a particular thin...   \n",
       "\n",
       "  veridicality  acceptability  nativeenglish  exclude  \n",
       "0        maybe              6           True    False  \n",
       "1          yes              2           True    False  \n",
       "2        maybe              4           True    False  \n",
       "3          yes              4           True    False  \n",
       "4        maybe              3           True    False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver = ver[~ver.conditional]\n",
    "\n",
    "ver.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we remove NA responses, which arise from MTurk errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver = ver[~ver.veridicality.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Generation\n",
    "\n",
    "Next, we add a column containing the hypothesis corresponding to each item. This is just the declarative form of the question that participants were asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>list</th>\n",
       "      <th>presentationorder</th>\n",
       "      <th>verb</th>\n",
       "      <th>frame</th>\n",
       "      <th>voice</th>\n",
       "      <th>polarity</th>\n",
       "      <th>conditional</th>\n",
       "      <th>sentence</th>\n",
       "      <th>veridicality</th>\n",
       "      <th>acceptability</th>\n",
       "      <th>nativeenglish</th>\n",
       "      <th>exclude</th>\n",
       "      <th>hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>surmise</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone surmised that a particular thing happened</td>\n",
       "      <td>maybe</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>That thing happened.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>update</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone updated that a particular thing happened</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>That thing happened.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>disregard</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone didn\\'t disregard that a particular th...</td>\n",
       "      <td>maybe</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>That thing happened.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>agree</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone agreed that a particular thing happened</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>That thing happened.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>surmise</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone didn\\'t surmise that a particular thin...</td>\n",
       "      <td>maybe</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>That thing happened.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  list  presentationorder       verb   frame   voice  polarity  \\\n",
       "0          487     0                  1    surmise  that_S  active  positive   \n",
       "1          487     0                  2     update  that_S  active  positive   \n",
       "2          487     0                  3  disregard  that_S  active  negative   \n",
       "3          487     0                  4      agree  that_S  active  positive   \n",
       "4          487     0                  5    surmise  that_S  active  negative   \n",
       "\n",
       "   conditional                                           sentence  \\\n",
       "0        False  Someone surmised that a particular thing happened   \n",
       "1        False   Someone updated that a particular thing happened   \n",
       "2        False  Someone didn\\'t disregard that a particular th...   \n",
       "3        False    Someone agreed that a particular thing happened   \n",
       "4        False  Someone didn\\'t surmise that a particular thin...   \n",
       "\n",
       "  veridicality  acceptability  nativeenglish  exclude            hypothesis  \n",
       "0        maybe              6           True    False  That thing happened.  \n",
       "1          yes              2           True    False  That thing happened.  \n",
       "2        maybe              4           True    False  That thing happened.  \n",
       "3          yes              4           True    False  That thing happened.  \n",
       "4        maybe              3           True    False  That thing happened.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_hypothesis(frame):\n",
    "    if frame in ['that_S', 'for_NP_to_VP']:\n",
    "        return 'That thing happened.'\n",
    "    elif frame in ['to_VPeventive', 'NP_to_VPeventive']:\n",
    "        return 'That person did that thing.'\n",
    "    elif frame in ['to_VPstative', 'NP_to_VPstative']:\n",
    "        return 'That person had that thing.'\n",
    "    \n",
    "ver['hypothesis'] = ver.frame.map(make_hypothesis)\n",
    "\n",
    "ver.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column hashing\n",
    "\n",
    "We then convert the response itself to an integer: _no_ = 0, _maybe_ = 1, _yes_ = 2. This is necessary for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>list</th>\n",
       "      <th>presentationorder</th>\n",
       "      <th>verb</th>\n",
       "      <th>frame</th>\n",
       "      <th>voice</th>\n",
       "      <th>polarity</th>\n",
       "      <th>conditional</th>\n",
       "      <th>sentence</th>\n",
       "      <th>veridicality</th>\n",
       "      <th>acceptability</th>\n",
       "      <th>nativeenglish</th>\n",
       "      <th>exclude</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>surmise</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone surmised that a particular thing happened</td>\n",
       "      <td>maybe</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>That thing happened.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>update</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone updated that a particular thing happened</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>That thing happened.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>disregard</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone didn\\'t disregard that a particular th...</td>\n",
       "      <td>maybe</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>That thing happened.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>agree</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone agreed that a particular thing happened</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>That thing happened.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>surmise</td>\n",
       "      <td>that_S</td>\n",
       "      <td>active</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>Someone didn\\'t surmise that a particular thin...</td>\n",
       "      <td>maybe</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>That thing happened.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  list  presentationorder       verb   frame   voice  polarity  \\\n",
       "0          487     0                  1    surmise  that_S  active  positive   \n",
       "1          487     0                  2     update  that_S  active  positive   \n",
       "2          487     0                  3  disregard  that_S  active  negative   \n",
       "3          487     0                  4      agree  that_S  active  positive   \n",
       "4          487     0                  5    surmise  that_S  active  negative   \n",
       "\n",
       "   conditional                                           sentence  \\\n",
       "0        False  Someone surmised that a particular thing happened   \n",
       "1        False   Someone updated that a particular thing happened   \n",
       "2        False  Someone didn\\'t disregard that a particular th...   \n",
       "3        False    Someone agreed that a particular thing happened   \n",
       "4        False  Someone didn\\'t surmise that a particular thin...   \n",
       "\n",
       "  veridicality  acceptability  nativeenglish  exclude            hypothesis  \\\n",
       "0        maybe              6           True    False  That thing happened.   \n",
       "1          yes              2           True    False  That thing happened.   \n",
       "2        maybe              4           True    False  That thing happened.   \n",
       "3          yes              4           True    False  That thing happened.   \n",
       "4        maybe              3           True    False  That thing happened.   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       2  \n",
       "2       1  \n",
       "3       2  \n",
       "4       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver['veridicality'] = ver.veridicality.astype(CategoricalDtype(['no', 'maybe', 'yes']))\n",
    "ver['target'] = ver.veridicality.cat.codes\n",
    "\n",
    "ver.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We similarly convert the participant indices to contiguous integers. This step is necessary since we removed some participants, meaning the participant identifiers are not necessarily contiguous. This conversion is necessary for the random effects component of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver['participant'] = ver.participant.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority response\n",
    "\n",
    "Lastly, we compute the modal response for each verb-frame pair. This will allow us to determine how well the model does in comparison to the best possible model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6535400834164939"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver['modal_response'] = ver.groupby(['verb', 'frame']).target.transform(lambda x: int(np.round(np.mean(x))))\n",
    "(ver.target == ver.modal_response).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MegaNegRaising\n",
    "\n",
    "Next, we pull the [MegaNegRaising v1](http://megaattitude.io/projects/mega-negraising/) data from the [MegaAttitude website](http://megaattitude.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>list</th>\n",
       "      <th>presentationorder</th>\n",
       "      <th>verb</th>\n",
       "      <th>frame</th>\n",
       "      <th>tense</th>\n",
       "      <th>subject</th>\n",
       "      <th>sentence</th>\n",
       "      <th>negraising</th>\n",
       "      <th>acceptability</th>\n",
       "      <th>nativeenglish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>229</td>\n",
       "      <td>81</td>\n",
       "      <td>8</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V that S</td>\n",
       "      <td>past</td>\n",
       "      <td>first</td>\n",
       "      <td>I didn't abhor that a particular thing happened.</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259</td>\n",
       "      <td>81</td>\n",
       "      <td>15</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V that S</td>\n",
       "      <td>past</td>\n",
       "      <td>first</td>\n",
       "      <td>I didn't abhor that a particular thing happened.</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.34</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>883</td>\n",
       "      <td>81</td>\n",
       "      <td>14</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V that S</td>\n",
       "      <td>past</td>\n",
       "      <td>first</td>\n",
       "      <td>I didn't abhor that a particular thing happened.</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.71</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>665</td>\n",
       "      <td>81</td>\n",
       "      <td>22</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V that S</td>\n",
       "      <td>past</td>\n",
       "      <td>first</td>\n",
       "      <td>I didn't abhor that a particular thing happened.</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>901</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V that S</td>\n",
       "      <td>past</td>\n",
       "      <td>first</td>\n",
       "      <td>I didn't abhor that a particular thing happened.</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.61</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  list  presentationorder   verb        frame tense subject  \\\n",
       "0          229    81                  8  abhor  NP V that S  past   first   \n",
       "1          259    81                 15  abhor  NP V that S  past   first   \n",
       "2          883    81                 14  abhor  NP V that S  past   first   \n",
       "3          665    81                 22  abhor  NP V that S  past   first   \n",
       "4          901    81                 12  abhor  NP V that S  past   first   \n",
       "\n",
       "                                           sentence  negraising  \\\n",
       "0  I didn't abhor that a particular thing happened.        0.30   \n",
       "1  I didn't abhor that a particular thing happened.        0.09   \n",
       "2  I didn't abhor that a particular thing happened.        0.50   \n",
       "3  I didn't abhor that a particular thing happened.        0.00   \n",
       "4  I didn't abhor that a particular thing happened.        0.33   \n",
       "\n",
       "   acceptability  nativeenglish  \n",
       "0           0.97           True  \n",
       "1           0.34           True  \n",
       "2           0.71           True  \n",
       "3           0.87           True  \n",
       "4           0.61           True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_url = 'http://megaattitude.io/projects/mega-negraising/mega-negraising-v1/mega-negraising-v1.tsv'\n",
    "\n",
    "neg = pd.read_csv(neg_url, sep='\\t')\n",
    "\n",
    "neg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Generation\n",
    "\n",
    "To generate the hypotheses, it is useful to use the sentences found in [MegaAcceptability v2](http://megaattitude.io/projects/mega-acceptability/). And so we pull those data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>list</th>\n",
       "      <th>presentationorder</th>\n",
       "      <th>verb</th>\n",
       "      <th>frame</th>\n",
       "      <th>tense</th>\n",
       "      <th>response</th>\n",
       "      <th>nativeenglish</th>\n",
       "      <th>sentence</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>504</td>\n",
       "      <td>13</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V</td>\n",
       "      <td>past</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Someone abhorred.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>638</td>\n",
       "      <td>504</td>\n",
       "      <td>13</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V</td>\n",
       "      <td>past</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Someone abhorred.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>504</td>\n",
       "      <td>13</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V</td>\n",
       "      <td>past</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Someone abhorred.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>336</td>\n",
       "      <td>504</td>\n",
       "      <td>13</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V</td>\n",
       "      <td>past</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Someone abhorred.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>339</td>\n",
       "      <td>504</td>\n",
       "      <td>13</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V</td>\n",
       "      <td>past</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Someone abhorred.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  list  presentationorder   verb frame tense  response  \\\n",
       "0          192   504                 13  abhor  NP V  past       7.0   \n",
       "1          638   504                 13  abhor  NP V  past       3.0   \n",
       "2          200   504                 13  abhor  NP V  past       1.0   \n",
       "3          336   504                 13  abhor  NP V  past       3.0   \n",
       "4          339   504                 13  abhor  NP V  past       4.0   \n",
       "\n",
       "   nativeenglish           sentence  version  \n",
       "0           True  Someone abhorred.        1  \n",
       "1           True  Someone abhorred.        1  \n",
       "2           True  Someone abhorred.        1  \n",
       "3           True  Someone abhorred.        1  \n",
       "4           True  Someone abhorred.        1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_url = 'http://megaattitude.io/projects/mega-acceptability/mega-acceptability-v2/mega-acceptability-v2.tsv'\n",
    "\n",
    "acc = pd.read_csv(acc_url, sep='\\t')\n",
    "\n",
    "acc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this data for hypothesis generation requires that we have access to the verb lemma and verb form found in the sentence. These functions extract that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx(sentence, tense, template, verblemma):\n",
    "    tokens = sentence.split()\n",
    "    lemmasplit = verblemma.split('_')\n",
    "    idx = np.where([w=='V' for w in template.split()])[0][0]\n",
    "    \n",
    "    if template == 'S, I V':\n",
    "        if len(lemmasplit) > 1:\n",
    "            return [len(tokens)-3, len(tokens)-2]\n",
    "        else:\n",
    "            return [len(tokens)-2]\n",
    "        \n",
    "    elif tense == 'past_progressive':\n",
    "        \n",
    "        if len(lemmasplit) > 1:\n",
    "            return [idx+1, idx+2]\n",
    "        else:\n",
    "            return [idx+1]\n",
    "        \n",
    "    else:\n",
    "        if len(lemmasplit) > 1:\n",
    "            return [idx, idx+1]\n",
    "        else:\n",
    "            return [idx]\n",
    "\n",
    "def get_verb_form(sentence, idx):\n",
    "    tokens = np.array(sentence.split())\n",
    "    return ' '.join([c.replace('.', '') for t in tokens[idx] for c in t.split('_')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then extract that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>list</th>\n",
       "      <th>presentationorder</th>\n",
       "      <th>verb</th>\n",
       "      <th>frame</th>\n",
       "      <th>tense</th>\n",
       "      <th>response</th>\n",
       "      <th>nativeenglish</th>\n",
       "      <th>sentence</th>\n",
       "      <th>version</th>\n",
       "      <th>verbidx</th>\n",
       "      <th>verbform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>504</td>\n",
       "      <td>13</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V</td>\n",
       "      <td>past</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Someone abhorred.</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>abhorred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>638</td>\n",
       "      <td>504</td>\n",
       "      <td>13</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V</td>\n",
       "      <td>past</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Someone abhorred.</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>abhorred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>504</td>\n",
       "      <td>13</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V</td>\n",
       "      <td>past</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Someone abhorred.</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>abhorred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>336</td>\n",
       "      <td>504</td>\n",
       "      <td>13</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V</td>\n",
       "      <td>past</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Someone abhorred.</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>abhorred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>339</td>\n",
       "      <td>504</td>\n",
       "      <td>13</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V</td>\n",
       "      <td>past</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Someone abhorred.</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>abhorred</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  list  presentationorder   verb frame tense  response  \\\n",
       "0          192   504                 13  abhor  NP V  past       7.0   \n",
       "1          638   504                 13  abhor  NP V  past       3.0   \n",
       "2          200   504                 13  abhor  NP V  past       1.0   \n",
       "3          336   504                 13  abhor  NP V  past       3.0   \n",
       "4          339   504                 13  abhor  NP V  past       4.0   \n",
       "\n",
       "   nativeenglish           sentence  version verbidx  verbform  \n",
       "0           True  Someone abhorred.        1     [1]  abhorred  \n",
       "1           True  Someone abhorred.        1     [1]  abhorred  \n",
       "2           True  Someone abhorred.        1     [1]  abhorred  \n",
       "3           True  Someone abhorred.        1     [1]  abhorred  \n",
       "4           True  Someone abhorred.        1     [1]  abhorred  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc['verbidx'] = acc[['sentence', 'tense', 'frame', 'verb']].apply(lambda x: get_idx(*x), axis=1)\n",
    "acc['verbform'] = acc[['sentence', 'verbidx']].apply(lambda x: get_verb_form(*x), axis=1)\n",
    "\n",
    "acc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we just care about the mapping from verb, frame, and tense to sentence, we drop all the other columns, de-dupe, and rename the sentence column to `hypothesis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>verbform</th>\n",
       "      <th>frame</th>\n",
       "      <th>tense</th>\n",
       "      <th>hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abhor</td>\n",
       "      <td>abhorred</td>\n",
       "      <td>NP V</td>\n",
       "      <td>past</td>\n",
       "      <td>Someone abhorred.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abhor</td>\n",
       "      <td>abhorred</td>\n",
       "      <td>NP V NP</td>\n",
       "      <td>past</td>\n",
       "      <td>Someone abhorred something.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abhor</td>\n",
       "      <td>abhorring</td>\n",
       "      <td>NP V NP</td>\n",
       "      <td>past_progressive</td>\n",
       "      <td>Someone was abhorring something.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abhor</td>\n",
       "      <td>abhors</td>\n",
       "      <td>NP V NP</td>\n",
       "      <td>present</td>\n",
       "      <td>Someone abhors something.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abhor</td>\n",
       "      <td>abhorred</td>\n",
       "      <td>NP V NP VP</td>\n",
       "      <td>past</td>\n",
       "      <td>Someone abhorred someone do something.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    verb   verbform       frame             tense  \\\n",
       "0  abhor   abhorred        NP V              past   \n",
       "1  abhor   abhorred     NP V NP              past   \n",
       "2  abhor  abhorring     NP V NP  past_progressive   \n",
       "3  abhor     abhors     NP V NP           present   \n",
       "4  abhor   abhorred  NP V NP VP              past   \n",
       "\n",
       "                               hypothesis  \n",
       "0                       Someone abhorred.  \n",
       "1             Someone abhorred something.  \n",
       "2        Someone was abhorring something.  \n",
       "3               Someone abhors something.  \n",
       "4  Someone abhorred someone do something.  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_map = acc[['verb', 'verbform', 'frame', 'tense', 'sentence']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "sentence_map = sentence_map.rename(columns={'sentence': 'hypothesis'})\n",
    "\n",
    "sentence_map.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add the negation in to make the neg-raising hypotheses and then add them to the neg-raising data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>list</th>\n",
       "      <th>presentationorder</th>\n",
       "      <th>verb</th>\n",
       "      <th>frame</th>\n",
       "      <th>tense</th>\n",
       "      <th>subject</th>\n",
       "      <th>sentence</th>\n",
       "      <th>negraising</th>\n",
       "      <th>acceptability</th>\n",
       "      <th>nativeenglish</th>\n",
       "      <th>verbform</th>\n",
       "      <th>hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>229</td>\n",
       "      <td>81</td>\n",
       "      <td>8</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V that S</td>\n",
       "      <td>past</td>\n",
       "      <td>first</td>\n",
       "      <td>I didn't abhor that a particular thing happened.</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>True</td>\n",
       "      <td>abhorred</td>\n",
       "      <td>Someone abhorred that that thing didn't happen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259</td>\n",
       "      <td>81</td>\n",
       "      <td>15</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V that S</td>\n",
       "      <td>past</td>\n",
       "      <td>first</td>\n",
       "      <td>I didn't abhor that a particular thing happened.</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.34</td>\n",
       "      <td>True</td>\n",
       "      <td>abhorred</td>\n",
       "      <td>Someone abhorred that that thing didn't happen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>883</td>\n",
       "      <td>81</td>\n",
       "      <td>14</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V that S</td>\n",
       "      <td>past</td>\n",
       "      <td>first</td>\n",
       "      <td>I didn't abhor that a particular thing happened.</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.71</td>\n",
       "      <td>True</td>\n",
       "      <td>abhorred</td>\n",
       "      <td>Someone abhorred that that thing didn't happen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>665</td>\n",
       "      <td>81</td>\n",
       "      <td>22</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V that S</td>\n",
       "      <td>past</td>\n",
       "      <td>first</td>\n",
       "      <td>I didn't abhor that a particular thing happened.</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>True</td>\n",
       "      <td>abhorred</td>\n",
       "      <td>Someone abhorred that that thing didn't happen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>901</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP V that S</td>\n",
       "      <td>past</td>\n",
       "      <td>first</td>\n",
       "      <td>I didn't abhor that a particular thing happened.</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.61</td>\n",
       "      <td>True</td>\n",
       "      <td>abhorred</td>\n",
       "      <td>Someone abhorred that that thing didn't happen.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  list  presentationorder   verb        frame tense subject  \\\n",
       "0          229    81                  8  abhor  NP V that S  past   first   \n",
       "1          259    81                 15  abhor  NP V that S  past   first   \n",
       "2          883    81                 14  abhor  NP V that S  past   first   \n",
       "3          665    81                 22  abhor  NP V that S  past   first   \n",
       "4          901    81                 12  abhor  NP V that S  past   first   \n",
       "\n",
       "                                           sentence  negraising  \\\n",
       "0  I didn't abhor that a particular thing happened.        0.30   \n",
       "1  I didn't abhor that a particular thing happened.        0.09   \n",
       "2  I didn't abhor that a particular thing happened.        0.50   \n",
       "3  I didn't abhor that a particular thing happened.        0.00   \n",
       "4  I didn't abhor that a particular thing happened.        0.33   \n",
       "\n",
       "   acceptability  nativeenglish  verbform  \\\n",
       "0           0.97           True  abhorred   \n",
       "1           0.34           True  abhorred   \n",
       "2           0.71           True  abhorred   \n",
       "3           0.87           True  abhorred   \n",
       "4           0.61           True  abhorred   \n",
       "\n",
       "                                        hypothesis  \n",
       "0  Someone abhorred that that thing didn't happen.  \n",
       "1  Someone abhorred that that thing didn't happen.  \n",
       "2  Someone abhorred that that thing didn't happen.  \n",
       "3  Someone abhorred that that thing didn't happen.  \n",
       "4  Someone abhorred that that thing didn't happen.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_map['hypothesis'] = sentence_map.hypothesis.str.replace('something happened.', \"that thing didn't happen.\")\n",
    "sentence_map['hypothesis'] = sentence_map.hypothesis.str.replace('to do something.', \"not to do that thing.\")\n",
    "sentence_map['hypothesis'] = sentence_map.hypothesis.str.replace('to have something.', \"not to have that thing.\")\n",
    "\n",
    "neg = pd.merge(neg, sentence_map)\n",
    "\n",
    "neg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need to do is convert the subject to first person when the neg-raising sentence being judged has a first person subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>list</th>\n",
       "      <th>presentationorder</th>\n",
       "      <th>verb</th>\n",
       "      <th>frame</th>\n",
       "      <th>tense</th>\n",
       "      <th>subject</th>\n",
       "      <th>sentence</th>\n",
       "      <th>negraising</th>\n",
       "      <th>acceptability</th>\n",
       "      <th>nativeenglish</th>\n",
       "      <th>verbform</th>\n",
       "      <th>hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1012</td>\n",
       "      <td>39</td>\n",
       "      <td>18</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP be V that S</td>\n",
       "      <td>present</td>\n",
       "      <td>first</td>\n",
       "      <td>I'm not abhorred that a particular thing happe...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>True</td>\n",
       "      <td>abhorred</td>\n",
       "      <td>I'm abhorred that that thing didn't happen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1018</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP be V that S</td>\n",
       "      <td>present</td>\n",
       "      <td>first</td>\n",
       "      <td>I'm not abhorred that a particular thing happe...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>True</td>\n",
       "      <td>abhorred</td>\n",
       "      <td>I'm abhorred that that thing didn't happen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>265</td>\n",
       "      <td>39</td>\n",
       "      <td>17</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP be V that S</td>\n",
       "      <td>present</td>\n",
       "      <td>first</td>\n",
       "      <td>I'm not abhorred that a particular thing happe...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>True</td>\n",
       "      <td>abhorred</td>\n",
       "      <td>I'm abhorred that that thing didn't happen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>488</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP be V that S</td>\n",
       "      <td>present</td>\n",
       "      <td>first</td>\n",
       "      <td>I'm not abhorred that a particular thing happe...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.64</td>\n",
       "      <td>True</td>\n",
       "      <td>abhorred</td>\n",
       "      <td>I'm abhorred that that thing didn't happen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>643</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>abhor</td>\n",
       "      <td>NP be V that S</td>\n",
       "      <td>present</td>\n",
       "      <td>first</td>\n",
       "      <td>I'm not abhorred that a particular thing happe...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>True</td>\n",
       "      <td>abhorred</td>\n",
       "      <td>I'm abhorred that that thing didn't happen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78845</th>\n",
       "      <td>550</td>\n",
       "      <td>209</td>\n",
       "      <td>28</td>\n",
       "      <td>yell</td>\n",
       "      <td>NP V to VP[+eventive]</td>\n",
       "      <td>present</td>\n",
       "      <td>first</td>\n",
       "      <td>I don't yell to do a particular thing.</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>True</td>\n",
       "      <td>yells</td>\n",
       "      <td>I yell not to do that thing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78846</th>\n",
       "      <td>377</td>\n",
       "      <td>209</td>\n",
       "      <td>31</td>\n",
       "      <td>yell</td>\n",
       "      <td>NP V to VP[+eventive]</td>\n",
       "      <td>present</td>\n",
       "      <td>first</td>\n",
       "      <td>I don't yell to do a particular thing.</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>yells</td>\n",
       "      <td>I yell not to do that thing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78847</th>\n",
       "      <td>937</td>\n",
       "      <td>209</td>\n",
       "      <td>30</td>\n",
       "      <td>yell</td>\n",
       "      <td>NP V to VP[+eventive]</td>\n",
       "      <td>present</td>\n",
       "      <td>first</td>\n",
       "      <td>I don't yell to do a particular thing.</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.31</td>\n",
       "      <td>True</td>\n",
       "      <td>yells</td>\n",
       "      <td>I yell not to do that thing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78848</th>\n",
       "      <td>771</td>\n",
       "      <td>209</td>\n",
       "      <td>25</td>\n",
       "      <td>yell</td>\n",
       "      <td>NP V to VP[+eventive]</td>\n",
       "      <td>present</td>\n",
       "      <td>first</td>\n",
       "      <td>I don't yell to do a particular thing.</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.41</td>\n",
       "      <td>True</td>\n",
       "      <td>yells</td>\n",
       "      <td>I yell not to do that thing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78849</th>\n",
       "      <td>470</td>\n",
       "      <td>209</td>\n",
       "      <td>26</td>\n",
       "      <td>yell</td>\n",
       "      <td>NP V to VP[+eventive]</td>\n",
       "      <td>present</td>\n",
       "      <td>first</td>\n",
       "      <td>I don't yell to do a particular thing.</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>yells</td>\n",
       "      <td>I yell not to do that thing.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14770 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       participant  list  presentationorder   verb                  frame  \\\n",
       "40            1012    39                 18  abhor         NP be V that S   \n",
       "41            1018    39                  3  abhor         NP be V that S   \n",
       "42             265    39                 17  abhor         NP be V that S   \n",
       "43             488    39                 10  abhor         NP be V that S   \n",
       "44             643    39                  3  abhor         NP be V that S   \n",
       "...            ...   ...                ...    ...                    ...   \n",
       "78845          550   209                 28   yell  NP V to VP[+eventive]   \n",
       "78846          377   209                 31   yell  NP V to VP[+eventive]   \n",
       "78847          937   209                 30   yell  NP V to VP[+eventive]   \n",
       "78848          771   209                 25   yell  NP V to VP[+eventive]   \n",
       "78849          470   209                 26   yell  NP V to VP[+eventive]   \n",
       "\n",
       "         tense subject                                           sentence  \\\n",
       "40     present   first  I'm not abhorred that a particular thing happe...   \n",
       "41     present   first  I'm not abhorred that a particular thing happe...   \n",
       "42     present   first  I'm not abhorred that a particular thing happe...   \n",
       "43     present   first  I'm not abhorred that a particular thing happe...   \n",
       "44     present   first  I'm not abhorred that a particular thing happe...   \n",
       "...        ...     ...                                                ...   \n",
       "78845  present   first             I don't yell to do a particular thing.   \n",
       "78846  present   first             I don't yell to do a particular thing.   \n",
       "78847  present   first             I don't yell to do a particular thing.   \n",
       "78848  present   first             I don't yell to do a particular thing.   \n",
       "78849  present   first             I don't yell to do a particular thing.   \n",
       "\n",
       "       negraising  acceptability  nativeenglish  verbform  \\\n",
       "40           0.00           0.27           True  abhorred   \n",
       "41           0.64           0.36           True  abhorred   \n",
       "42           0.76           0.56           True  abhorred   \n",
       "43           0.04           0.64           True  abhorred   \n",
       "44           0.58           0.58           True  abhorred   \n",
       "...           ...            ...            ...       ...   \n",
       "78845        0.00           0.60           True     yells   \n",
       "78846        0.69           0.00           True     yells   \n",
       "78847        0.27           0.31           True     yells   \n",
       "78848        0.63           0.41           True     yells   \n",
       "78849        0.00           1.00           True     yells   \n",
       "\n",
       "                                        hypothesis  \n",
       "40     I'm abhorred that that thing didn't happen.  \n",
       "41     I'm abhorred that that thing didn't happen.  \n",
       "42     I'm abhorred that that thing didn't happen.  \n",
       "43     I'm abhorred that that thing didn't happen.  \n",
       "44     I'm abhorred that that thing didn't happen.  \n",
       "...                                            ...  \n",
       "78845                 I yell not to do that thing.  \n",
       "78846                 I yell not to do that thing.  \n",
       "78847                 I yell not to do that thing.  \n",
       "78848                 I yell not to do that thing.  \n",
       "78849                 I yell not to do that thing.  \n",
       "\n",
       "[14770 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_subject(subject, tense, verb, frame, verbform, hypothesis):\n",
    "    if subject == 'first':\n",
    "        hypothesis = hypothesis.replace('Someone', 'I')\n",
    "        \n",
    "        if tense == 'present':\n",
    "            hypothesis = hypothesis.replace('I is', \"I'm\")\n",
    "            \n",
    "            if 'be' not in frame:\n",
    "                hypothesis = hypothesis.replace(verbform, verb)\n",
    "        \n",
    "        return hypothesis\n",
    "    else:\n",
    "        return hypothesis.replace('Someone', 'That person')\n",
    "    \n",
    "neg['hypothesis'] = neg[['subject', 'tense', 'verb', 'frame', 'verbform', 'hypothesis']].apply(lambda x: convert_subject(*x), axis=1)\n",
    "\n",
    "neg[(neg.subject=='first')&(neg.tense=='present')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Hashing\n",
    "\n",
    "As for MegaVeridicality, we need to map the participants to contiguous integers. The neg-raising slider response itself does not need to be changed, since it is already numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg['participant'] = neg.participant.astype('category').cat.codes\n",
    "neg['target'] = neg.negraising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Response\n",
    "\n",
    "We will be using a binary cross entrop loss, and the best possible response for this loss is the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6229927846085578"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg['modal_response'] = neg.groupby(['verb', 'frame', 'tense', 'subject']).negraising.transform(np.mean)\n",
    "\n",
    "-(neg.negraising * np.log(neg.modal_response) + (1-neg.negraising) * np.log(1-neg.modal_response)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/wgantt/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (decoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerSentenceEncoder(\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (emb_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta = torch.hub.load('pytorch/fairseq', 'roberta.base')\n",
    "roberta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I didn't accept that a particular thing happened. I accepted that that thing didn't happen.\n",
      "[\"I didn't accept that a particular thing happened.\", \"I accepted that that thing didn't happen.\"]\n"
     ]
    }
   ],
   "source": [
    "token_ids = roberta.encode(neg.loc[100,'sentence'], neg.loc[100,'hypothesis'])\n",
    "\n",
    "print(neg.loc[100,'sentence'], neg.loc[100,'hypothesis'])\n",
    "print(roberta.decode(token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 23, 768]),\n",
       " tensor([[[-0.1013,  0.0900, -0.0011,  ..., -0.1106, -0.0496, -0.0244],\n",
       "          [-0.0525,  0.0970, -0.0762,  ...,  0.2017, -0.1770,  0.0313],\n",
       "          [-0.0429,  0.1596, -0.0277,  ..., -0.1038, -0.2597,  0.1564],\n",
       "          ...,\n",
       "          [ 0.0680, -0.0329,  0.1913,  ..., -0.1216,  0.2177, -0.0265],\n",
       "          [-0.1008,  0.0795, -0.0270,  ..., -0.1501, -0.0499, -0.0519],\n",
       "          [-0.0529, -0.0010,  0.0384,  ..., -0.0635,  0.0235,  0.0492]]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    emb = roberta.extract_features(token_ids)\n",
    "    \n",
    "emb.shape, emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaturalLanguageInference(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim: int, n_predictor_layers: int,  \n",
    "                 output_dim: int, n_participants: int,\n",
    "                 use_random_slopes=False, device=torch.device('cpu')):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_predictor_layers = n_predictor_layers\n",
    "        self.output_dim = output_dim\n",
    "        self.n_participants = n_participants\n",
    "        self.use_random_slopes = use_random_slopes\n",
    "        self.device = device\n",
    "        \n",
    "        self._initialize_random_effects()\n",
    "        \n",
    "        # TODO: comment\n",
    "        if self.use_random_slopes:\n",
    "            self.predictor = self._initialize_predictor_for_random_slopes(self.n_participants)\n",
    "        else:\n",
    "            self.predictor = self._initialize_predictor()\n",
    "     \n",
    "    def _initialize_predictor(self):\n",
    "        seq = []\n",
    "        \n",
    "        prev_size = self.embedding_dim\n",
    "        \n",
    "        for l in range(self.n_predictor_layers):\n",
    "            curr_size = int(prev_size/2)\n",
    "                \n",
    "            seq += [Linear(prev_size,\n",
    "                           curr_size),\n",
    "                    ReLU(),\n",
    "                    Dropout(0.5)]\n",
    "\n",
    "            prev_size = curr_size\n",
    "\n",
    "        seq += [Linear(prev_size,\n",
    "                       self.output_dim)]\n",
    "        \n",
    "        return Sequential(*seq)\n",
    "\n",
    "    def _initialize_predictor_for_random_slopes(self, n_participants):\n",
    "        # Separate MLP for each annotator. We assume the annotator IDs\n",
    "        # are zero-indexed and range up to n_participants.\n",
    "        heads = []\n",
    "        for _ in range(n_participants):\n",
    "            seq = []\n",
    "            prev_size = self.embedding_dim\n",
    "        \n",
    "            for l in range(self.n_predictor_layers):\n",
    "                curr_size = int(prev_size/2)\n",
    "\n",
    "                seq += [Linear(prev_size,\n",
    "                               curr_size),\n",
    "                        ReLU(),\n",
    "                        Dropout(0.5)]\n",
    "\n",
    "                prev_size = curr_size\n",
    "\n",
    "            seq += [Linear(prev_size,\n",
    "                           self.output_dim)]\n",
    "            \n",
    "            heads.append(Sequential(*seq))\n",
    "            \n",
    "        return ModuleList(heads)\n",
    "        \n",
    "    def forward(self, embeddings, participant=None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        if self.use_random_slopes:\n",
    "            # Not sure this is right, but given that the *entire* prediction head\n",
    "            # is random, I don't know what would count as the fixed component.\n",
    "            # Maybe just the embedding?\n",
    "            fixed = None\n",
    "            \n",
    "            # In the random slopes setting, 'predictor' is actually a Tensor of \n",
    "            # n_participants MLPs, one for each participant. Couldn't figure out\n",
    "            # a way to vectorize this, unfortunately. This should probably go in\n",
    "            # the _random_effects method of a CategoricalNaturalLanguageInferenceRandomSlopes\n",
    "            # class.\n",
    "            random = torch.stack([self.predictor[p](e.mean(0)) for p, e in zip(participant, embeddings)], dim=0)\n",
    "            random_loss = self._random_loss(self._random_effects(participant))\n",
    "            \n",
    "        else:\n",
    "            fixed = self.predictor(embeddings.mean(1))\n",
    "        \n",
    "            if participant is None:\n",
    "                random = None\n",
    "                random_loss = 0.\n",
    "            else:\n",
    "                random = self._random_effects(participant)\n",
    "                random_loss = self._random_loss(random)\n",
    "        \n",
    "        prediction = self._link_function(fixed, random, participant)\n",
    "        \n",
    "        return prediction, random_loss\n",
    "\n",
    "    def embed(self, items: pd.DataFrame) -> torch.Tensor:\n",
    "        texts, hypotheses = items.sentence.values, items.hypothesis.values\n",
    "                \n",
    "        token_ids = collate_tokens([roberta.encode(t, h) \n",
    "                                    for t, h in zip(texts, hypotheses)], \n",
    "                                   pad_idx=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = roberta.extract_features(token_ids)\n",
    "            \n",
    "        return embedding\n",
    "\n",
    "class CategoricalNaturalLanguageInference(NaturalLanguageInference):\n",
    "    \n",
    "    def _initialize_random_effects(self):\n",
    "        self.random_effects = torch.randn(self.n_participants, self.output_dim)\n",
    "    \n",
    "    # Not sure why \"participant\" is a parameter here\n",
    "    def _random_effects(self, participant):\n",
    "        # No mean subtraction for random slopes\n",
    "        if self.use_random_slopes:\n",
    "            return self.random_effects\n",
    "        else:\n",
    "            return self.random_effects - self.random_effects.mean(0)[None,:]\n",
    "    \n",
    "    def _link_function(self, fixed, random, participant):\n",
    "        # Random slopes + random intercepts case\n",
    "        if fixed is None:\n",
    "            return random\n",
    "        # Fixed effects (standard setting)\n",
    "        elif random is None:\n",
    "            return fixed\n",
    "        # Random intercepts alone (extended setting)\n",
    "        else:\n",
    "            return fixed + random[participant]\n",
    "    \n",
    "    def _random_loss(self, random):\n",
    "        # TODO: Handle random slopes for tied covariance? May not be worth it.\n",
    "        print(random.std(0))\n",
    "        return torch.mean(torch.square(random/random.std(0)[None,:]))\n",
    "\n",
    "class CategoricalNaturalLanguageInferenceUntiedCovariance(CategoricalNaturalLanguageInference):\n",
    "    \n",
    "    def _random_loss(self, random):\n",
    "        # Random slopes + random intercepts: may have non-zero mean\n",
    "        if self.use_random_slopes:\n",
    "            mean = random.mean(0)\n",
    "            # This is currently incorrect\n",
    "            cov = torch.matmul(torch.transpose(random, 1, 0), random) / (self.n_participants - 1)\n",
    "        # Random intercepts only: mean is zero\n",
    "        else:\n",
    "            mean = torch.zeros(self.n_participants, self.output_dim)\n",
    "            cov = torch.matmul(torch.transpose(random, 1, 0), random) / (self.n_participants - 1)\n",
    "        return torch.mean(MultivariateNormal(mean, cov).log_prob(random)[None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.2562,  0.5619, -0.2292],\n",
       "         [ 2.4061, -0.1792,  0.0312]], grad_fn=<AddBackward0>),\n",
       " tensor(0.9000))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli = CategoricalNaturalLanguageInference(embedding_dim=768, n_predictor_layers=2, output_dim=3, n_participants=10)\n",
    "nli(torch.cat([emb, emb]), [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2046,  0.0377,  0.1039],\n",
       "         [ 0.0072,  0.0219, -0.0238]], grad_fn=<AddmmBackward>),\n",
       " 0.0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli(torch.cat([emb, emb]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-3cecb36dc8d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategoricalNaturalLanguageInferenceUntiedCovariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_predictor_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_participants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-734acd35613d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings, participant)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mrandom_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"participant shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mrandom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_effects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"random shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "nli = CategoricalNaturalLanguageInferenceUntiedCovariance(embedding_dim=768, n_predictor_layers=2, output_dim=3, n_participants=10)\n",
    "nli(torch.cat([emb, emb]), [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnitNaturalLanguageInference(NaturalLanguageInference):\n",
    "    \n",
    "    # TODO: Convert to using beta distribution\n",
    "    def _initialize_random_effects(self):\n",
    "        self.random_effects = torch.randn(self.n_participants, 2)\n",
    "        \n",
    "    def _random_effects(self, participant):\n",
    "        random_scale = torch.square(self.random_effects[:,0])\n",
    "        random_shift = self.random_effects[:,1] - self.random_effects[:,1].mean(0)\n",
    "        \n",
    "        return random_scale, random_shift\n",
    "    \n",
    "    def _link_function(self, fixed, random, participant):\n",
    "        if random is None:\n",
    "            return torch.square(self.random_effects[:,0]).mean()*fixed.squeeze(1)\n",
    "        else:\n",
    "            random_scale, random_shift = random\n",
    "            return (random_scale[participant][:,None]*fixed +\\\n",
    "                    random_shift[participant][:,None]).squeeze(1)\n",
    "    \n",
    "    def _random_loss(self, random):\n",
    "        random_scale, random_shift = random\n",
    "        \n",
    "        random_scale_loss = torch.mean(torch.square(random_scale/random_scale.mean(0)))\n",
    "        random_shift_loss = torch.mean(torch.square(random_shift/random_shift.std(0)))\n",
    "        print(random_scale)\n",
    "        \n",
    "        return (random_scale_loss + random_shift_loss)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnitNaturalLanguageInferenceRandomSlopes(NaturalLanguageInference):\n",
    "    \n",
    "    # TODO: implement\n",
    "    def _initialize_random_effects(self):\n",
    "        self.random_effects = torch.randn(self.n_participants, 2)\n",
    "        \n",
    "    def _random_effects(self, participant):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-546c26a18152>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnitNaturalLanguageInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_predictor_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_participants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-734acd35613d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings, participant)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mrandom_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"participant shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mrandom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_effects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"random shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "nli = UnitNaturalLanguageInference(embedding_dim=768, n_predictor_layers=2, output_dim=1, n_participants=10)\n",
    "nli(torch.cat([emb, emb]), [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 768])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli(torch.cat([emb, emb]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaturalLanguageInferenceTrainer:\n",
    "    \n",
    "    def __init__(self, n_participants: int, \n",
    "                 embedding_dim: int = 768, \n",
    "                 n_predictor_layers: int = 2,\n",
    "                 use_random_slopes: bool = False,\n",
    "                 device=torch.device('cpu')):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_predictor_layers = n_predictor_layers\n",
    "        self.n_participants = n_participants\n",
    "        self.device = device\n",
    "        self.use_random_slopes = use_random_slopes,\n",
    "        self.nli = self.MODEL_CLASS(embedding_dim, \n",
    "                                    n_predictor_layers,\n",
    "                                    self.OUTPUT_DIM, \n",
    "                                    n_participants,\n",
    "                                    use_random_slopes,\n",
    "                                    device)\n",
    "    \n",
    "    def fit(self, data: pd.DataFrame, batch_size: int = 32, \n",
    "            n_epochs: int = 10, lr: float = 1e-2, verbosity: int = 10):\n",
    "        \n",
    "        optimizer = Adam(self.nli.parameters(),\n",
    "                         lr=lr)\n",
    "        lossfunc = self.LOSS_CLASS()\n",
    "        \n",
    "        self.nli.train()\n",
    "        \n",
    "        n_batches = np.ceil(data.shape[0]/batch_size)\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            # shuffle the data\n",
    "            data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "            data['batch_idx'] = np.repeat(np.arange(n_batches), batch_size)[:data.shape[0]]\n",
    "            \n",
    "            loss_trace = []\n",
    "            acc_trace = []\n",
    "            best_trace = []\n",
    "            \n",
    "            for batch, items in data.groupby('batch_idx'):\n",
    "                self.nli.zero_grad()\n",
    "                \n",
    "                participant = torch.LongTensor(items.participant.values).to(self.device)\n",
    "                target = self.TARGET_TYPE(items.target.values)\n",
    "                \n",
    "                embedding = self.nli.embed(items)\n",
    "                \n",
    "                prediction, random_loss = self.nli(embedding, participant)\n",
    "            \n",
    "                fixed_loss = lossfunc(prediction, target)\n",
    "                \n",
    "                loss = fixed_loss + random_loss\n",
    "                \n",
    "                loss_trace.append(loss.item()-random_loss.item())\n",
    "                \n",
    "                if self.MODEL_CLASS is CategoricalNaturalLanguageInference:\n",
    "                    acc = (prediction.argmax(1) == target).data.cpu().numpy().mean()\n",
    "                    best = (items.modal_response==items.target).mean()\n",
    "                    \n",
    "                    acc_trace.append(acc)\n",
    "                    best_trace.append(acc/best)\n",
    "                \n",
    "                elif self.MODEL_CLASS is CategoricalNaturalLanguageInferenceUntiedCovariance:\n",
    "                    # Is the mean still the best possible performance in the random slopes case?\n",
    "                    # Something's fishy here when use_random_slopes = True, since the \"best\" loss\n",
    "                    # is often greater than the \n",
    "                    acc = (prediction.argmax(1) == target).data.cpu().numpy().mean()\n",
    "                    best = (items.modal_response==items.target).mean()\n",
    "                    \n",
    "                    acc_trace.append(acc)\n",
    "                    best_trace.append(acc/best)\n",
    "                    \n",
    "                elif self.MODEL_CLASS is UnitNaturalLanguageInference:\n",
    "                    acc = loss_trace[-1]\n",
    "                    best = -(items.target.values * np.log(items.modal_response.values) +\\\n",
    "                             (1-items.target.values) * np.log(1-items.modal_response.values)).mean()\n",
    "                    \n",
    "                    acc_trace.append(acc)\n",
    "                    best_trace.append(1 - (acc-best)/best)\n",
    "                \n",
    "                if not (batch % verbosity):\n",
    "                    print(f\"fixed loss: {fixed_loss}\")\n",
    "                    print(f\"random loss: {random_loss}\")\n",
    "                    print('epoch:              ', int(epoch))\n",
    "                    print('batch:              ', int(batch))\n",
    "                    print('mean loss:          ', np.round(np.mean(loss_trace), 2))\n",
    "                    print('mean acc.:          ', np.round(np.mean(acc_trace), 2))\n",
    "                    print('prop. best possible:', np.round(np.mean(best_trace), 2))\n",
    "                    print()\n",
    "                    \n",
    "                    print()\n",
    "\n",
    "                    loss_trace = []\n",
    "                    acc_trace = []\n",
    "                    best_trace = []\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "        return self.nli.eval()\n",
    "    \n",
    "    def calibrate(self, data: pd.DataFrame,\n",
    "                  trained_model: NaturalLanguageInference, \n",
    "                  calibrator_trainer_class: 'NaturalLanguageInferenceTrainer') -> NaturalLanguageInference:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        n_participants = data.participant.unique().shape[0]\n",
    "        \n",
    "        trained_model.eval()\n",
    "        \n",
    "        calibrator_trainer = calibrator_trainer_class(n_participants=n_participants,\n",
    "                                                      embedding_dim=trained_model.output_dim,\n",
    "                                                      n_predictor_layers=self.n_predictor_layers)\n",
    "        \n",
    "        calibrator = calibrator_trainer.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9914, 1.0290, 0.9344])\n",
      "fixed loss: 1.40700101852417\n",
      "random loss: 0.9980276823043823\n",
      "epoch:               0\n",
      "batch:               0\n",
      "mean loss:           1.41\n",
      "mean acc.:           0.34\n",
      "prop. best possible: 0.59\n",
      "\n",
      "\n",
      "tensor([0.9914, 1.0290, 0.9344])\n",
      "tensor([0.9914, 1.0290, 0.9344])\n",
      "fixed loss: 1.5120247602462769\n",
      "random loss: 0.9980276823043823\n",
      "epoch:               1\n",
      "batch:               0\n",
      "mean loss:           1.51\n",
      "mean acc.:           0.47\n",
      "prop. best possible: 0.76\n",
      "\n",
      "\n",
      "tensor([0.9914, 1.0290, 0.9344])\n",
      "tensor([0.9914, 1.0290, 0.9344])\n",
      "fixed loss: 1.3643431663513184\n",
      "random loss: 0.9980276823043823\n",
      "epoch:               2\n",
      "batch:               0\n",
      "mean loss:           1.36\n",
      "mean acc.:           0.36\n",
      "prop. best possible: 0.56\n",
      "\n",
      "\n",
      "tensor([0.9914, 1.0290, 0.9344])\n",
      "tensor([0.9914, 1.0290, 0.9344])\n",
      "fixed loss: 1.2718019485473633\n",
      "random loss: 0.9980276823043823\n",
      "epoch:               3\n",
      "batch:               0\n",
      "mean loss:           1.27\n",
      "mean acc.:           0.41\n",
      "prop. best possible: 0.71\n",
      "\n",
      "\n",
      "tensor([0.9914, 1.0290, 0.9344])\n",
      "tensor([0.9914, 1.0290, 0.9344])\n",
      "fixed loss: 1.3046817779541016\n",
      "random loss: 0.9980276823043823\n",
      "epoch:               4\n",
      "batch:               0\n",
      "mean loss:           1.3\n",
      "mean acc.:           0.43\n",
      "prop. best possible: 0.73\n",
      "\n",
      "\n",
      "tensor([0.9914, 1.0290, 0.9344])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-238-f23840da629b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcnli_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategoricalNaturalLanguageInferenceTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_participants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_ver_participants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m ver_model = cnli_trainer.fit(data=ver[ver.verb.isin([\"know\", 'think'])],\n\u001b[0;32m---> 11\u001b[0;31m                              n_epochs=25, batch_size=128)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-223-eff897c1cbd8>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, batch_size, n_epochs, lr, verbosity)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTARGET_TYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-237-e30b46931d56>\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroberta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/models/roberta/hub_interface.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, tokens, return_all_hiddens)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mfeatures_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/models/roberta/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_tokens, features_only, return_all_hiddens, classification_head_name, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mfeatures_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassification_head_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/models/roberta/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_tokens, features_only, return_all_hiddens, masked_tokens, **unused)\u001b[0m\n\u001b[1;32m    308\u001b[0m                   \u001b[0mstates\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfeatures_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasked_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/models/roberta/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, src_tokens, return_all_hiddens, **unused)\u001b[0m\n\u001b[1;32m    316\u001b[0m         inner_states, _ = self.sentence_encoder(\n\u001b[1;32m    317\u001b[0m             \u001b[0msrc_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mlast_state_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    320\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# T x B x C -> B x T x C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/modules/transformer_sentence_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens, segment_labels, last_state_only, positions)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mdropout_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdropout_probability\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayerdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_attn_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlast_state_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                     \u001b[0minner_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/modules/transformer_sentence_encoder_layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, self_attn_mask, self_attn_padding_mask)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         )\n\u001b[1;32m     80\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/modules/multihead_attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, incremental_state, need_weights, static_kv, attn_mask, before_softmax, need_head_weights)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mq_proj_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_proj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mk_proj_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mv_proj_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             )\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   3946\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3947\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3948\u001b[0;31m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1610\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class CategoricalNaturalLanguageInferenceTrainer(NaturalLanguageInferenceTrainer):\n",
    "    MODEL_CLASS = CategoricalNaturalLanguageInference\n",
    "    LOSS_CLASS = CrossEntropyLoss\n",
    "    TARGET_TYPE = torch.LongTensor\n",
    "    OUTPUT_DIM = 3\n",
    "\n",
    "n_ver_participants = ver.participant.unique().shape[0]\n",
    "    \n",
    "cnli_trainer = CategoricalNaturalLanguageInferenceTrainer(n_participants=n_ver_participants)\n",
    "ver_model = cnli_trainer.fit(data=ver[ver.verb.isin([\"know\", 'think'])],\n",
    "                             n_epochs=25, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Someone thought that a particular thing happened',\n",
       "  'That thing happened.',\n",
       "  array([0.00310725, 0.8000219 , 0.19687088], dtype=float32)),\n",
       " (\"Someone didn\\\\'t think that a particular thing happened\",\n",
       "  'That thing happened.',\n",
       "  array([0.39985964, 0.5714444 , 0.02869605], dtype=float32)),\n",
       " ('Someone knew that a particular thing happened',\n",
       "  'That thing happened.',\n",
       "  array([6.890681e-07, 2.588863e-02, 9.741107e-01], dtype=float32)),\n",
       " (\"Someone didn\\\\'t know that a particular thing happened\",\n",
       "  'That thing happened.',\n",
       "  array([0.03967796, 0.44767112, 0.5126509 ], dtype=float32))]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = ver[(ver.verb.isin(['think', 'know']))&(ver.frame=='that_S')][['verb', 'frame', 'sentence', 'hypothesis']].drop_duplicates()\n",
    "embedding = ver_model.embed(items)\n",
    "\n",
    "list(zip(items.sentence.values, items.hypothesis.values, torch.softmax(ver_model(embedding)[0], 1).data.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9461,  0.0122, -0.0895],\n",
      "        [ 0.0122,  1.0064,  0.0334],\n",
      "        [-0.0895,  0.0334,  1.0127]])\n",
      "fixed loss: 1.4101446866989136\n",
      "random loss: -4.230784893035889\n",
      "epoch:               0\n",
      "batch:               0\n",
      "mean loss:           1.41\n",
      "mean acc.:           0.32\n",
      "prop. best possible: 0.53\n",
      "\n",
      "\n",
      "tensor([[ 0.9461,  0.0122, -0.0895],\n",
      "        [ 0.0122,  1.0064,  0.0334],\n",
      "        [-0.0895,  0.0334,  1.0127]])\n",
      "tensor([[ 0.9461,  0.0122, -0.0895],\n",
      "        [ 0.0122,  1.0064,  0.0334],\n",
      "        [-0.0895,  0.0334,  1.0127]])\n",
      "fixed loss: 1.295589566230774\n",
      "random loss: -4.230784893035889\n",
      "epoch:               1\n",
      "batch:               0\n",
      "mean loss:           1.3\n",
      "mean acc.:           0.43\n",
      "prop. best possible: 0.75\n",
      "\n",
      "\n",
      "tensor([[ 0.9461,  0.0122, -0.0895],\n",
      "        [ 0.0122,  1.0064,  0.0334],\n",
      "        [-0.0895,  0.0334,  1.0127]])\n",
      "tensor([[ 0.9461,  0.0122, -0.0895],\n",
      "        [ 0.0122,  1.0064,  0.0334],\n",
      "        [-0.0895,  0.0334,  1.0127]])\n",
      "fixed loss: 1.3057492971420288\n",
      "random loss: -4.230784893035889\n",
      "epoch:               2\n",
      "batch:               0\n",
      "mean loss:           1.31\n",
      "mean acc.:           0.39\n",
      "prop. best possible: 0.68\n",
      "\n",
      "\n",
      "tensor([[ 0.9461,  0.0122, -0.0895],\n",
      "        [ 0.0122,  1.0064,  0.0334],\n",
      "        [-0.0895,  0.0334,  1.0127]])\n",
      "tensor([[ 0.9461,  0.0122, -0.0895],\n",
      "        [ 0.0122,  1.0064,  0.0334],\n",
      "        [-0.0895,  0.0334,  1.0127]])\n",
      "fixed loss: 1.1719460487365723\n",
      "random loss: -4.230784893035889\n",
      "epoch:               3\n",
      "batch:               0\n",
      "mean loss:           1.17\n",
      "mean acc.:           0.52\n",
      "prop. best possible: 0.89\n",
      "\n",
      "\n",
      "tensor([[ 0.9461,  0.0122, -0.0895],\n",
      "        [ 0.0122,  1.0064,  0.0334],\n",
      "        [-0.0895,  0.0334,  1.0127]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-236-b431898b9221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcnli_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategoricalNaturalLanguageInferenceUntiedCovarianceTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_participants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_ver_participants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_random_slopes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m ver_model = cnli_trainer.fit(data=ver[ver.verb.isin([\"know\", 'think'])],\n\u001b[0;32m---> 11\u001b[0;31m                              n_epochs=25, batch_size=128)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-223-eff897c1cbd8>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, batch_size, n_epochs, lr, verbosity)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTARGET_TYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-235-b57da13f1270>\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroberta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/models/roberta/hub_interface.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, tokens, return_all_hiddens)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mfeatures_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/models/roberta/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_tokens, features_only, return_all_hiddens, classification_head_name, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mfeatures_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassification_head_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/models/roberta/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_tokens, features_only, return_all_hiddens, masked_tokens, **unused)\u001b[0m\n\u001b[1;32m    308\u001b[0m                   \u001b[0mstates\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfeatures_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasked_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/models/roberta/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, src_tokens, return_all_hiddens, **unused)\u001b[0m\n\u001b[1;32m    316\u001b[0m         inner_states, _ = self.sentence_encoder(\n\u001b[1;32m    317\u001b[0m             \u001b[0msrc_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mlast_state_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    320\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# T x B x C -> B x T x C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/modules/transformer_sentence_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens, segment_labels, last_state_only, positions)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mdropout_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdropout_probability\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayerdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_attn_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlast_state_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                     \u001b[0minner_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/modules/transformer_sentence_encoder_layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, self_attn_mask, self_attn_padding_mask)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1610\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class CategoricalNaturalLanguageInferenceUntiedCovarianceTrainer(NaturalLanguageInferenceTrainer):\n",
    "    MODEL_CLASS = CategoricalNaturalLanguageInferenceUntiedCovariance\n",
    "    LOSS_CLASS = CrossEntropyLoss\n",
    "    TARGET_TYPE = torch.LongTensor\n",
    "    OUTPUT_DIM = 3\n",
    "\n",
    "n_ver_participants = ver.participant.unique().shape[0]\n",
    "    \n",
    "cnli_trainer = CategoricalNaturalLanguageInferenceUntiedCovarianceTrainer(n_participants=n_ver_participants, use_random_slopes=False)\n",
    "ver_model = cnli_trainer.fit(data=ver[ver.verb.isin([\"know\", 'think'])],\n",
    "                             n_epochs=25, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = ver[(ver.verb.isin(['think', 'know']))&(ver.frame=='that_S')][['verb', 'frame', 'sentence', 'hypothesis']].drop_duplicates()\n",
    "embedding = ver_model.embed(items)\n",
    "\n",
    "list(zip(items.sentence.values, items.hypothesis.values, torch.softmax(ver_model(embedding)[0], 1).data.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6621, 0.5234, 0.7755,  ..., 0.0270, 0.8010, 0.9642])\n",
      "fixed loss: 0.8863546848297119\n",
      "random loss: 1.948185682296753\n",
      "epoch:               0\n",
      "batch:               0\n",
      "mean loss:           0.89\n",
      "mean acc.:           0.89\n",
      "prop. best possible: 0.57\n",
      "\n",
      "\n",
      "tensor([1.6621, 0.5234, 0.7755,  ..., 0.0270, 0.8010, 0.9642])\n",
      "tensor([1.6621, 0.5234, 0.7755,  ..., 0.0270, 0.8010, 0.9642])\n",
      "tensor([1.6621, 0.5234, 0.7755,  ..., 0.0270, 0.8010, 0.9642])\n",
      "fixed loss: 0.8896234631538391\n",
      "random loss: 1.948185682296753\n",
      "epoch:               1\n",
      "batch:               0\n",
      "mean loss:           0.89\n",
      "mean acc.:           0.89\n",
      "prop. best possible: 0.59\n",
      "\n",
      "\n",
      "tensor([1.6621, 0.5234, 0.7755,  ..., 0.0270, 0.8010, 0.9642])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-240-7b5915eef613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0munli_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnitNaturalLanguageInferenceTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_participants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_neg_participants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m neg_model = unli_trainer.fit(data=neg[neg.verb.isin(['think', 'know'])], \n\u001b[0;32m---> 11\u001b[0;31m                              n_epochs=100, batch_size=128, lr=1-1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-223-eff897c1cbd8>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, batch_size, n_epochs, lr, verbosity)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTARGET_TYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-237-e30b46931d56>\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroberta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/models/roberta/hub_interface.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, tokens, return_all_hiddens)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mfeatures_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/models/roberta/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_tokens, features_only, return_all_hiddens, classification_head_name, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mfeatures_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassification_head_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/models/roberta/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_tokens, features_only, return_all_hiddens, masked_tokens, **unused)\u001b[0m\n\u001b[1;32m    308\u001b[0m                   \u001b[0mstates\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfeatures_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasked_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/models/roberta/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, src_tokens, return_all_hiddens, **unused)\u001b[0m\n\u001b[1;32m    316\u001b[0m         inner_states, _ = self.sentence_encoder(\n\u001b[1;32m    317\u001b[0m             \u001b[0msrc_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mlast_state_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mreturn_all_hiddens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    320\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# T x B x C -> B x T x C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/modules/transformer_sentence_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens, segment_labels, last_state_only, positions)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mdropout_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdropout_probability\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayerdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_attn_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlast_state_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                     \u001b[0minner_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/fairseq/fairseq/modules/transformer_sentence_encoder_layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, self_attn_mask, self_attn_padding_mask)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1610\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class UnitNaturalLanguageInferenceTrainer(NaturalLanguageInferenceTrainer):\n",
    "    MODEL_CLASS = UnitNaturalLanguageInference\n",
    "    LOSS_CLASS = BCEWithLogitsLoss\n",
    "    TARGET_TYPE = torch.FloatTensor\n",
    "    OUTPUT_DIM = 1\n",
    "\n",
    "n_neg_participants = neg.participant.unique().shape[0]\n",
    "\n",
    "unli_trainer = UnitNaturalLanguageInferenceTrainer(n_participants=n_neg_participants)\n",
    "neg_model = unli_trainer.fit(data=neg[neg.verb.isin(['think', 'know'])], \n",
    "                             n_epochs=100, batch_size=128, lr=1-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = neg[neg.verb.isin(['think', 'know'])][['verb', 'frame', 'sentence', 'hypothesis']].drop_duplicates()\n",
    "embedding = neg_model.embed(items)\n",
    "\n",
    "list(zip(items.sentence.values, items.hypothesis.values, torch.sigmoid(neg_model(embedding)[0]).data.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_model.random_effects[:,0].square().mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
